{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construcción y calibración de árboles de decisión\n",
    "\n",
    "En este notebook aprenderá a construir árboles de decisión de dos maneras: uno, desarrollando el código manualmente; y dos, usando la librería especializada sklearn. Así mismo aprenderá a calibrarlos y a obtener la importancia de las variables para la predicción. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones Generales:\n",
    "\n",
    "El árbol de decisión que construirá por medio de este notebook deberá predecir si el salario de un beisbolista es alto (>425) dadas las variables de desempeño en su carrera. Por esta razón, los datos a usar en el notebook son los de las Grandes Ligas de Béisbol de las temporadas 1986 y 1987, para más detalles: https://rdrr.io/cran/ISLR/man/Hitters.html. \n",
    "\n",
    "Para realizar la actividad, solo siga las indicaciones asociadas a cada celda del notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar base de datos y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carga de datos de archivos .csv\n",
    "url = 'https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/hitters.csv'\n",
    "hitters = pd.read_csv(url)\n",
    "\n",
    "# Eliminación filas con observaciones nulas\n",
    "hitters.dropna(inplace=True)\n",
    "hitters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificar variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitters['League'] = pd.factorize(hitters.League)[0]\n",
    "hitters['Division'] = pd.factorize(hitters.Division)[0]\n",
    "hitters['NewLeague'] = pd.factorize(hitters.NewLeague)[0]\n",
    "hitters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar la información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica del salario, años y hits\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "hitters.plot(kind='scatter', x='Years', y='Hits', c='Salary', colormap='jet', xlim=(0, 25), ylim=(0, 250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir las varibles del problema - Predictores y varible de respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de variables predictoras\n",
    "feature_cols = hitters.columns[hitters.columns.str.startswith('C') == False].drop('Salary')\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción de la variable de respuesta 'Salary'\n",
    "hitters.Salary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interes (y)\n",
    "X = hitters[feature_cols]\n",
    "y = (hitters.Salary > 425).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir un árbol de decisión manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de parámetros y criterios de parada\n",
    "max_depth = None\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: para la primera variable ('Hits') se calculan los posibles puntos de corte y el gini index de un punto especifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impresión variable a usar (Hits)\n",
    "j = 1\n",
    "print(X.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de la variable Hits en num_ctp puntos (parámetro definido anteriormente) para obtener posibles puntos de corte\n",
    "splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / num_pct).tolist())\n",
    "splits = np.unique(splits)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de las observaciones usando el punto de corte en la posición 5 de la lista de splits\n",
    "k=5\n",
    "filter_l = X.iloc[:, j] < splits[k]\n",
    "\n",
    "# División de la variable de respuesta de acuerdo a si la observación cumple o no con la regla binaria\n",
    "# y_l: la observación tiene un valor menor al punto de corte seleccionado\n",
    "# y_r: la observación tiene un valor mayor o igual al punto de corte seleccionado\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función que calcula el gini index\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini index de las observaciones que tienen un valor menor al punto de corte seleccionado\n",
    "gini_l = gini(y_l)\n",
    "gini_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gini index de las observaciones que tienen un valor mayor o igual al punto de corte seleccionado\n",
    "gini_r = gini(y_r)\n",
    "gini_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función gini_imputiry para calular la ganancia de una variable predictora j dado el punto de corte k\n",
    "def gini_impurity(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ganancia de la variable 'Hits' en el punto de corte selecionado\n",
    "gini_impurity(X.iloc[:, j], y, splits[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para todas las variables se calculan sus posibles puntos de corte y se selecciona aquella que de la menor impureza o ganancia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función best_split para calcular cuál es la mejor variable y punto de cortepara hacer la bifurcación del árbol\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtención de la variable 'j', su punto de corte 'split' y su ganancia 'gain'\n",
    "j, split, gain = best_split(X, y, 5)\n",
    "j, split, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de las observaciones usando la mejor variable 'j' y su punto de corte 'split'\n",
    "filter_l = X.iloc[:, j] < split\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape[0], y_l.shape[0], y_r.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean(), y_l.mean(), y_r.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crecimiento recursivo del árbol "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función tree_grow para hacer un crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de la función tree_grow\n",
    "tree_grow(X, y, level=0, min_gain=0.001, max_depth=1, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree_grow(X, y, level=0, min_gain=0.001, max_depth=3, num_pct=10)\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizar predicciones usando el árbol creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función tree_predict para hacer predicciones según las variables 'X' y el árbol 'tree'\n",
    "\n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución de función tree_predict\n",
    "tree_predict(X, tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir un árbol de decisiones usando *Sklearn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de valores para calibrar el criterio de parada de máxima profundidad (max_depth)\n",
    "max_depth_range = range(1, 21)\n",
    "\n",
    "# Lista para guardar los valores del RMSE para cada valor de máxima profundidad (max_depth)\n",
    "accuracy_scores = []\n",
    "\n",
    "# Importación de modelos de sklearn \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loop para obtener el desempeño del modelo de acuerdo con la máxima profundidad\n",
    "for depth in max_depth_range:\n",
    "    # Definición del árbol de decisión usando DecisionTreeClassifier de la libreria sklearn\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica max_depth versus RMSE (error del modelo)\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor accuracy (desempeño del modelo) y su correspondiente max_depth\n",
    "sorted(zip(accuracy_scores, max_depth_range))[::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=4 fue el mejor, se ajusta un árbol usando este valor \n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importancia de las variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso de la función .feature_importances_ para obtener la importancia de cada variable\n",
    "pd.DataFrame({'feature':feature_cols, 'importance':clf.feature_importances_}).sort_values('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impresión de resultados de desemepeño del árbol de decisión\n",
    "pd.Series(cross_val_score(clf, X, y, cv=10)).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
